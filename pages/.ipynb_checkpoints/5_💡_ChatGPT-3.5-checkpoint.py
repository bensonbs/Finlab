import os
import openai
import streamlit as st
from opencc import OpenCC

# å‰µå»ºä¸€å€‹ç°¡ç¹è½‰æ›çš„å¯¦ä¾‹
cc = OpenCC('s2t')

# Setting page title and header
st.set_page_config(page_title="ChatGPT", page_icon="ğŸ’¡")
st.markdown("<h1 style='text-align: center;'>ğŸ’¡ ChatGPT</h1>", unsafe_allow_html=True)

# Set OpenAI API key from Streamlit secrets
openai.api_key = os.environ['OPENAI_API_KEY']

# Set a default model
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"
    # st.session_state["openai_model"] = 'gpt-4'

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({"role": "user", "content": 'ç°¡çŸ­å›ç­”å•é¡Œï¼Œä¸¦é¿å…å›ç­”é‡è¤‡å…§å®¹'})
    st.session_state.messages.append({"role": "assistant", "content": 'æ˜¯çš„ï¼Œæˆ‘æœƒç°¡çŸ­å›ç­”'})

with st.chat_message("assistant"):
    ('æœ¬å¹³å°ä¸ä¿å­˜ä»»ä½•æ•¸æ“šğŸ˜‰ï¼Œè®“æˆ‘å€‘é–‹å§‹å§ã€‚')
        
# Display chat messages from history on app rerun
for message in st.session_state.messages[2:]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
# Accept user input
if prompt := st.chat_input("What is up?"):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    # Display user message in chat message container
    with st.chat_message("user"):
        st.markdown(prompt)
    # Display assistant response in chat message container
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
    
        # å˜—è©¦ä»¥ä¸‹çš„æ“ä½œï¼Œè‹¥å‡ºç¾éŒ¯èª¤å‰‡æ•æ‰ä¸¦é¡¯ç¤ºè­¦å‘Š
        try:
            # åˆå§‹åŒ–å…¨é«”å›æ‡‰å…§å®¹
            full_response = ""
            
            # å°‡sessionä¸­çš„è¨Šæ¯è½‰æ›æˆé©åˆOpenAI Chatæ¨¡å‹çš„å½¢å¼
            model_input = []
            for m in st.session_state.messages[-3:]:
                message_dict = {"role": m["role"], "content": m["content"]}
                model_input.append(message_dict)
        
            
            # å‰µå»ºä¸€å€‹chatå®Œæˆå¯¦ä¾‹ä¸¦ä»¥streamæ¨¡å¼æ¥æ”¶çµæœï¼Œæœ€å¤§tokenæ•¸ç‚º1024
            chat_completion = openai.ChatCompletion.create(
                    model=st.session_state["openai_model"],
                    messages=model_input,
                    stream=True,
                    max_tokens=1024
                )
            
            # è¿­ä»£è™•ç†chatå®Œæˆå¯¦ä¾‹çš„å›æ‡‰å…§å®¹ï¼Œä¸¦å°‡å…§å®¹åŠ åˆ°å…¨é«”å›æ‡‰ä¸­
            for response in chat_completion:
                response_content = response.choices[0].delta.get("content", "")
                response_content = cc.convert(response_content)
                full_response += response_content
                message_placeholder.markdown(full_response + " ")
        
            # å°‡æœ€çµ‚çš„å…¨é«”å›æ‡‰é¡¯ç¤ºå‡ºä¾†
            message_placeholder.markdown(full_response)
        
            # å°‡å›æ‡‰åŠ åˆ°sessionçš„è¨Šæ¯åˆ—è¡¨ä¸­
            st.session_state.messages.append({"role": "assistant", "content": full_response})
    
        # è‹¥åœ¨ä¸Šè¿°éç¨‹ä¸­å‡ºç¾ä»»ä½•éŒ¯èª¤ï¼Œå‰‡é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
        except:
            st.warning('ğŸ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡æ–°æ•´ç†')
